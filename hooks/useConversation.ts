import { useState } from 'react';
import { Platform } from 'react-native';
import { tokenStorage } from '@/services/api/axios';

export interface ConversationMessage {
  id: string;
  timestamp: string;
  originalText: string;
  originalLanguage: string;
  translatedText: string;
  translatedLanguage: string;
  confidence: number;
  audioData?: string;
}

export const useConversation = () => {
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [conversationId, setConversationId] = useState<string | null>(null);
  const [messages, setMessages] = useState<ConversationMessage[]>([]);
  const [selectedLanguage, setSelectedLanguage] = useState<string>('en-US');
  const [isPlayingAudio, setIsPlayingAudio] = useState(false);

  const supportedLanguages = [
    { code: 'en-US', name: 'ì˜ì–´ (English)', flag: 'ğŸ‡ºğŸ‡¸' },
    { code: 'vi-VN', name: 'ë² íŠ¸ë‚¨ì–´ (Tiáº¿ng Viá»‡t)', flag: 'ğŸ‡»ğŸ‡³' },
    { code: 'th-TH', name: 'íƒœêµ­ì–´ (à¹„à¸—à¸¢)', flag: 'ğŸ‡¹ğŸ‡­' },
    { code: 'km-KH', name: 'í¬ë©”ë¥´ì–´ (á—á¶áŸá¶ááŸ’á˜áŸ‚áš)', flag: 'ğŸ‡°ğŸ‡­' },
  ];



  const processConversation = async (audioUri: string) => {
    setIsLoading(true);
    setError(null);
    
    try {
      
      // URIì—ì„œ Blob ìƒì„± (React Native)
      const audioBlob = await fetch(audioUri).then(r => r.blob());
      
      // FormData ìƒì„±
      const formData = new FormData();
      
      // React Nativeì—ì„œ íŒŒì¼ ì—…ë¡œë“œ
      const fileUpload = {
        uri: audioUri,
        type: audioBlob.type || 'audio/wav',
        name: 'recording.wav'
      };
      
      formData.append('audio', fileUpload as any);
      formData.append('selectedForeignLanguage', selectedLanguage);
      
      if (conversationId) {
        formData.append('conversationId', conversationId);
      }
      
      // JWT í† í° ê°€ì ¸ì˜¤ê¸°
      const token = await tokenStorage.getAccessToken();
      
      if (!token) {
        throw new Error('ì¸ì¦ í† í°ì´ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë¡œê·¸ì¸í•´ì£¼ì„¸ìš”.');
      }
      
      // fetchë¡œ ì§ì ‘ ìš”ì²­
      const headers: Record<string, string> = {
        'Authorization': `Bearer ${token}`,
      };
      
      const response = await fetch(`${process.env.EXPO_PUBLIC_API_BASE_URL}/api/speech/conversation`, {
        method: 'POST',
        headers,
        body: formData,
      });
      
      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(`HTTP ${response.status}: ${errorText}`);
      }
      
      const result = await response.json();
      
      // ìƒˆë¡œìš´ ì‘ë‹µ êµ¬ì¡°ì— ë§ê²Œ ë°ì´í„° ì¶”ì¶œ
      const responseData = result.data;
      const message = responseData.message;
      
      const newMessage: ConversationMessage = {
        id: message.id,
        timestamp: message.timestamp,
        originalText: message.originalText,
        originalLanguage: message.originalLanguage,
        translatedText: message.translatedText || '',
        translatedLanguage: message.translatedLanguage || selectedLanguage,
        confidence: 1.0,
        audioData: message.audioData,
      };
      
      // ëŒ€í™” ID ì„¤ì •
      if (!conversationId) {
        setConversationId(responseData.conversationId);
      }
      
      // ë©”ì‹œì§€ ì¶”ê°€
      setMessages(prev => [...prev, newMessage]);
      
      // ë²ˆì—­ëœ ìŒì„± ìë™ ì¬ìƒ (TTS ê²°ê³¼)
      if (newMessage.audioData) {
        await playTranslatedAudio(newMessage.audioData);
      }
      return newMessage;
    } catch (err) {
      const errorMessage = err instanceof Error ? err.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.';
      setError(errorMessage);
      throw err;
    } finally {
      setIsLoading(false);
    }
  };

  const playTranslatedAudio = async (audioData: string) => {
    try {
      setIsPlayingAudio(true);
      
      if (Platform.OS === 'web') {
        // ì›¹ì—ì„œëŠ” ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
        const audioBytes = Uint8Array.from(atob(audioData), c => c.charCodeAt(0));
        const audioBlob = new Blob([audioBytes], { type: 'audio/mpeg' });
        
        const audioUrl = URL.createObjectURL(audioBlob);
        const audio = new Audio(audioUrl);
        
        audio.onended = () => {
          setIsPlayingAudio(false);
          URL.revokeObjectURL(audioUrl);
        };
        
        audio.onerror = () => {
          setIsPlayingAudio(false);
          URL.revokeObjectURL(audioUrl);
        };
        
        await audio.play();
      } else {
        // React Nativeì—ì„œëŠ” expo-av ì‚¬ìš©
        try {
          const { Audio } = await import('expo-av');
          
          // base64ë¥¼ data URIë¡œ ë³€í™˜
          const audioUri = `data:audio/mpeg;base64,${audioData}`;
          
          // Sound ê°ì²´ ìƒì„± ë° ì¬ìƒ
          const { sound } = await Audio.Sound.createAsync(
            { uri: audioUri },
            { shouldPlay: true }
          );
          
          // ì¬ìƒ ì™„ë£Œ ì‹œ ì½œë°±
          sound.setOnPlaybackStatusUpdate((status) => {
            if (status.isLoaded) {
              if (status.didJustFinish) {
                setIsPlayingAudio(false);
                sound.unloadAsync(); // ë©”ëª¨ë¦¬ ì •ë¦¬
              }
            } else if (status.error) {
              setIsPlayingAudio(false);
            }
          });
        } catch (nativeError) {
          setIsPlayingAudio(false);
        }
      }
    } catch (err) {
      setIsPlayingAudio(false);
    }
  };

  const playMessageAudio = async (audioData: string) => {
    await playTranslatedAudio(audioData);
  };

  const clearConversation = () => {
    setMessages([]);
    setConversationId(null);
    setError(null);
  };

  const changeLanguage = (languageCode: string) => {
    setSelectedLanguage(languageCode);
  };

  return {
    isLoading,
    error,
    conversationId,
    messages,
    selectedLanguage,
    supportedLanguages,
    isPlayingAudio,
    processConversation,
    playMessageAudio,
    clearConversation,
    changeLanguage,
  };
}; 